{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Hist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - CODE  \n",
    "    &ensp; : Crawling - 특일 정보 조회 (KASI)\n",
    "\n",
    "  - DATE  \n",
    "    &ensp; 2023-11-29 Created  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 1)   \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 2)    \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 3)   \n",
    "    \n",
    " - DESC  \n",
    "    &ensp; : 전처리 - 한국지역난방공사 열판매량/열공급량   \n",
    "    &emsp; 1) 결측치가 없어서, 그대로 사용  \n",
    "    &emsp;&ensp;&ensp; \n",
    "    &emsp;&ensp;&ensp; (Crawl Code 없음)   \n",
    "    &emsp; 2) \n",
    "\n",
    " - DATA  \n",
    "    &emsp; <\"Input\">  \n",
    "    1) None (Input Dataset)  \n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval : \n",
    "\n",
    "    &emsp; <\"Output\">  \n",
    "    1) Hourly (관측소/년도별 출력)  \n",
    "    &nbsp;df_data_cal.to_csv(data_dir + 'KASI_DATE_D_Final.csv', index = False, encoding='utf-8-sig')  \n",
    "    &emsp;- Columns : ['YEAR', 'MONTH', 'DAY'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'dateKind', 'code_day_of_the_week', 'day_of_the_week'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'rest_YN', 'name_of_holiday', 'dist_from_holiday']\n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval :  \n",
    "    \n",
    "    2) Daily (관측소/년도별 출력)  \n",
    "    &nbsp;df_data_cal_24.to_csv(data_dir + 'KASI_DATE_H_Final.csv', index = False, encoding='utf-8-sig')  \n",
    "    &emsp;- Columns : ['locdate', 'YEAR', 'MONTH', 'DAY'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'dateKind', 'code_day_of_the_week', 'day_of_the_week'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'rest_YN', 'name_of_holiday', 'dist_from_holiday'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'HOUR', 'MINUTE']\n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval :  \n",
    "    \n",
    "    \n",
    "\n",
    " - Related Link  \n",
    "    &ensp; : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-01. Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-01. Init_Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region Basic_Import\n",
    "## Basic\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "## Datetime\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import glob\n",
    "from glob import glob\n",
    "import requests\n",
    "import json\n",
    "\n",
    "## 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "## TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## 정규화\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "## Modeling, Model Training\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "## Model 평가\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score   # model.score   \n",
    "\n",
    "## Excel/CSV\n",
    "import openpyxl, xlrd\n",
    "\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode, unquote, quote_plus\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## Init.\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "#endregion Basic_Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Imported\n"
     ]
    }
   ],
   "source": [
    "## Import_DL\n",
    "str_tar = \"torch\"\n",
    "## For Torch\n",
    "if str_tar == \"torch\":\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.nn.utils import weight_norm\n",
    "    print(\"Torch Imported\")\n",
    "## For TF\n",
    "elif str_tar == \"tf\":\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_addons as tfa\n",
    "    print(\"Tensorflow Imported\")\n",
    "else:\n",
    "    print(\"Error : Cannot be used except for Keywords\")\n",
    "    print(\" : torch / tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Model\n",
    "# from tensorflow.python.keras.models import Sequential\n",
    "# from tensorflow.python.keras.layers import Dense, Flatten\n",
    "# from tensorflow.python.keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "# multivariate data preparation\n",
    "from numpy import array, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import_Local (현재 프로그램에서 미사용)\n",
    "from DEV_Common_Data_Analysis import print_desc_statistic\n",
    "from DEV_Common_Data_Datetime import create_col_ymdhm, create_col_datetime, create_df_dt, conv_midnight_24to00, create_col_weekdays #, validate_date, list_invalidDate, calc_df_dt\n",
    "from DEV_Common_Data_Preprocessing import resample_by_last, find_outlier_Usages, del_outlier_Usages\n",
    "from DEV_Common_Data_Visualization import visualization_df\n",
    "from DEV_KASI_Holiday import KASI_holiDay, KASI_restDay, KASI_anniDay\n",
    "from DEV_KMA_Weather_ASOS import KMA_ASOS_DATA\n",
    "from DEV_KDHC_Usage import KDHC_HEAT_Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-02. Config (Directory, Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init_config\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-05 18:59:03.908913\n",
      "2024 / 1 / 5\n",
      "18 : 59\n"
     ]
    }
   ],
   "source": [
    "## Define Todate str\n",
    "str_now_ymd = pd.datetime.now().date()\n",
    "str_now_y = pd.datetime.now().year\n",
    "str_now_m = pd.datetime.now().month\n",
    "str_now_d = pd.datetime.now().day\n",
    "str_now_hr = pd.datetime.now().hour\n",
    "str_now_min = pd.datetime.now().minute\n",
    "\n",
    "print(pd.datetime.now())\n",
    "print(str(str_now_y) + \" / \" + str(str_now_m)  + \" / \" + str(str_now_d))\n",
    "print(str(str_now_hr) + \" : \" + str(str_now_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-02. Data Load (df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-02-01. KDHC Heat Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['METER_DATE', 'YEAR', 'MONTH', 'DAY', 'code_day_of_the_week', 'rest_YN',\n",
      "       'dist_from_holiday', 'HOUR', 'PAJU', 'GOYANG', 'SAMSONG', 'JOONGANG',\n",
      "       'KANGNAM', 'PANGYO', 'BUNDANG', 'YONGIN', 'GWANGGYO', 'SUWON',\n",
      "       'HWASUNG', 'DONGTAN', 'PYONGTAEK', 'CHEONGJU', 'SEJONG', 'KIMHAE',\n",
      "       'DAEGU', 'YANGSAN', 'GWANGJU_JEONNAM'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define data root directory\n",
    "str_dir_kdhcHeat = \"./data_Energy_KDHC_National_Heat/\"\n",
    "# print(os.listdir(str_dir_kdhcHeat))\n",
    "\n",
    "df_kdhc_heat = pd.read_csv(str_dir_kdhcHeat + 'KDHC_COMB_HEATxWEATHER_2019-2022.csv', index_col = 0)\n",
    "df_kdhc_heat = df_kdhc_heat[['METER_DATE', 'YEAR', 'MONTH', 'DAY', 'code_day_of_the_week', 'rest_YN', 'dist_from_holiday'\n",
    "                             ,'HOUR'\n",
    "                            #  , 'temp_outdoor', 'temp_dew_point', 'temp_ground'\n",
    "                            #  , 'humidity'\n",
    "                            #  , 'rainfall'\n",
    "                            #  , 'snowfall', 'snowfall_3hr'\n",
    "                            #  , 'wind_speed', 'wind_direction'\n",
    "                            #  , 'pressure_vapor', 'pressure_area', 'pressure_sea'\n",
    "                            #  , 'visual_range'\n",
    "                             , 'PAJU', 'GOYANG', 'SAMSONG', 'JOONGANG'\n",
    "                             , 'KANGNAM'\n",
    "                             , 'PANGYO', 'BUNDANG', 'YONGIN', 'GWANGGYO', 'SUWON', 'HWASUNG', 'DONGTAN', 'PYONGTAEK', 'CHEONGJU', 'SEJONG'\n",
    "                             , 'KIMHAE', 'DAEGU', 'YANGSAN'\n",
    "                             , 'GWANGJU_JEONNAM']]\n",
    "## 어디서 중복 생긴건지 확인 필요\n",
    "df_kdhc_heat = df_kdhc_heat.drop_duplicates()\n",
    "\n",
    "df_kdhc_heat['METER_DATE'] = pd.to_datetime(df_kdhc_heat['METER_DATE'])\n",
    "df_dt = df_kdhc_heat['METER_DATE']\n",
    "\n",
    "## 추출된 \"DATE\"로부터 Week를 계산\n",
    "# df_kdhc_heat['WEEK'] = df_kdhc_heat['METER_DATE'].dt.strftime('%G-%V') \n",
    "\n",
    "for i in range(0, len(df_kdhc_heat)):\n",
    "    ## 중간에 Code화 되지 않은 rest_YN Data가 있다.\n",
    "    if((str(df_kdhc_heat['rest_YN'].iloc[i]) == 'N') | (df_kdhc_heat['rest_YN'].iloc[i] == '0')):\n",
    "        df_kdhc_heat['rest_YN'].iloc[i] = 0\n",
    "    if((str(df_kdhc_heat['rest_YN'].iloc[i]) == 'Y') | (df_kdhc_heat['rest_YN'].iloc[i] == '1')):\n",
    "        df_kdhc_heat['rest_YN'].iloc[i] = 1\n",
    "\n",
    "    ## 중간에 이상하게 처리된 KASI Data가 있다.\n",
    "    if((str(df_kdhc_heat['dist_from_holiday'].iloc[i]) == '제헌절')\n",
    "        | (str(df_kdhc_heat['dist_from_holiday'].iloc[i]) == '한글날')):\n",
    "        df_kdhc_heat['dist_from_holiday'].iloc[i] = 0\n",
    "\n",
    "df_kdhc_heat['rest_YN'] = df_kdhc_heat['rest_YN'].astype('int64')\n",
    "df_kdhc_heat['dist_from_holiday'] = df_kdhc_heat['rest_YN'].astype('int64')\n",
    "\n",
    "print(df_kdhc_heat.columns)\n",
    "# df_kdhc_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_considered = ['PAJU', 'GOYANG', 'SAMSONG', 'JOONGANG'\n",
    "#                        , 'KANGNAM'\n",
    "#                        , 'PANGYO', 'BUNDANG', 'YONGIN', 'GWANGGYO', 'SUWON', 'HWASUNG', 'DONGTAN', 'PYONGTAEK', 'CHEONGJU', 'SEJONG'\n",
    "#                        , 'KIMHAE', 'DAEGU', 'YANGSAN'\n",
    "#                        , 'GWANGJU_JEONNAM']\n",
    "# features = df_kdhc_heat[features_considered]\n",
    "# features.index = df_kdhc_heat['METER_DATE']\n",
    "\n",
    "# features.plot(subplots=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(figsize=(30,5))\n",
    "\n",
    "# ax1.plot(df_dt, df_kdhc_heat['PAJU'], color='red')\n",
    "\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.plot(df_dt, df_kdhc_heat['GOYANG'], color='green')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        x = data.iloc[i:(i+seq_length)]\n",
    "        y = data.iloc[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>rest_YN</th>\n",
       "      <th>code_day_of_the_week</th>\n",
       "      <th>dist_from_holiday</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>PAJU</th>\n",
       "      <th>GOYANG</th>\n",
       "      <th>SAMSONG</th>\n",
       "      <th>...</th>\n",
       "      <th>SUWON</th>\n",
       "      <th>HWASUNG</th>\n",
       "      <th>DONGTAN</th>\n",
       "      <th>PYONGTAEK</th>\n",
       "      <th>CHEONGJU</th>\n",
       "      <th>SEJONG</th>\n",
       "      <th>KIMHAE</th>\n",
       "      <th>DAEGU</th>\n",
       "      <th>YANGSAN</th>\n",
       "      <th>GWANGJU_JEONNAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>76.0000000000</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0000000000</td>\n",
       "      <td>27.0000000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>34.0000000000</td>\n",
       "      <td>10</td>\n",
       "      <td>34.0000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>69.0000000000</td>\n",
       "      <td>17.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0000000000</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>21</td>\n",
       "      <td>23.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>30.0000000000</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>58.0000000000</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0000000000</td>\n",
       "      <td>17.0000000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>18</td>\n",
       "      <td>16.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>23.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>49.0000000000</td>\n",
       "      <td>14.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0000000000</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>17</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>51.0000000000</td>\n",
       "      <td>10.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0000000000</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>15</td>\n",
       "      <td>17.0000000000</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27178</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>103.0000000000</td>\n",
       "      <td>44.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0000000000</td>\n",
       "      <td>43.0000000000</td>\n",
       "      <td>60</td>\n",
       "      <td>10.0000000000</td>\n",
       "      <td>32</td>\n",
       "      <td>56.0000000000</td>\n",
       "      <td>13</td>\n",
       "      <td>49.0000000000</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27179</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>95.0000000000</td>\n",
       "      <td>40.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0000000000</td>\n",
       "      <td>41.0000000000</td>\n",
       "      <td>58</td>\n",
       "      <td>9.0000000000</td>\n",
       "      <td>32</td>\n",
       "      <td>59.0000000000</td>\n",
       "      <td>14</td>\n",
       "      <td>39.0000000000</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27180</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>99.0000000000</td>\n",
       "      <td>34.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0000000000</td>\n",
       "      <td>35.0000000000</td>\n",
       "      <td>46</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>37</td>\n",
       "      <td>57.0000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>40.0000000000</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27181</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>85.0000000000</td>\n",
       "      <td>27.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0000000000</td>\n",
       "      <td>26.0000000000</td>\n",
       "      <td>37</td>\n",
       "      <td>6.0000000000</td>\n",
       "      <td>33</td>\n",
       "      <td>48.0000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>33.0000000000</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27302</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>84.0000000000</td>\n",
       "      <td>30.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0000000000</td>\n",
       "      <td>22.0000000000</td>\n",
       "      <td>26</td>\n",
       "      <td>5.0000000000</td>\n",
       "      <td>21</td>\n",
       "      <td>38.0000000000</td>\n",
       "      <td>11</td>\n",
       "      <td>32.0000000000</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8401 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       YEAR  MONTH  DAY  rest_YN  code_day_of_the_week  dist_from_holiday  \\\n",
       "94     2019     10    3        1                     3                  1   \n",
       "96     2019     10    3        1                     3                  1   \n",
       "98     2019     10    3        1                     3                  1   \n",
       "100    2019     10    3        1                     3                  1   \n",
       "102    2019     10    3        1                     3                  1   \n",
       "...     ...    ...  ...      ...                   ...                ...   \n",
       "27178  2022      9   25        1                     6                  1   \n",
       "27179  2022      9   25        1                     6                  1   \n",
       "27180  2022      9   25        1                     6                  1   \n",
       "27181  2022      9   25        1                     6                  1   \n",
       "27302  2022     10    1        1                     5                  1   \n",
       "\n",
       "       HOUR  PAJU         GOYANG       SAMSONG  ...         SUWON  \\\n",
       "94        0    19  76.0000000000 18.0000000000  ... 37.0000000000   \n",
       "96        1    31  69.0000000000 17.0000000000  ... 40.0000000000   \n",
       "98        2    22  58.0000000000 18.0000000000  ... 31.0000000000   \n",
       "100       3    22  49.0000000000 14.0000000000  ... 25.0000000000   \n",
       "102       4    22  51.0000000000 10.0000000000  ... 21.0000000000   \n",
       "...     ...   ...            ...           ...  ...           ...   \n",
       "27178    20    18 103.0000000000 44.0000000000  ... 59.0000000000   \n",
       "27179    21    19  95.0000000000 40.0000000000  ... 61.0000000000   \n",
       "27180    22    16  99.0000000000 34.0000000000  ... 58.0000000000   \n",
       "27181    23    13  85.0000000000 27.0000000000  ... 48.0000000000   \n",
       "27302     0    28  84.0000000000 30.0000000000  ... 63.0000000000   \n",
       "\n",
       "            HWASUNG  DONGTAN     PYONGTAEK  CHEONGJU        SEJONG  KIMHAE  \\\n",
       "94    27.0000000000       27  0.0000000000        29 34.0000000000      10   \n",
       "96    19.0000000000       16  1.0000000000        21 23.0000000000       8   \n",
       "98    17.0000000000       17  1.0000000000        18 16.0000000000       8   \n",
       "100   18.0000000000       16  1.0000000000        17 18.0000000000       7   \n",
       "102   19.0000000000       13  1.0000000000        15 17.0000000000       7   \n",
       "...             ...      ...           ...       ...           ...     ...   \n",
       "27178 43.0000000000       60 10.0000000000        32 56.0000000000      13   \n",
       "27179 41.0000000000       58  9.0000000000        32 59.0000000000      14   \n",
       "27180 35.0000000000       46  6.0000000000        37 57.0000000000      12   \n",
       "27181 26.0000000000       37  6.0000000000        33 48.0000000000      12   \n",
       "27302 22.0000000000       26  5.0000000000        21 38.0000000000      11   \n",
       "\n",
       "              DAEGU  YANGSAN  GWANGJU_JEONNAM  \n",
       "94    34.0000000000       12                4  \n",
       "96    30.0000000000       11                4  \n",
       "98    23.0000000000        8                3  \n",
       "100   18.0000000000        8                3  \n",
       "102   18.0000000000        8                3  \n",
       "...             ...      ...              ...  \n",
       "27178 49.0000000000       23               14  \n",
       "27179 39.0000000000       29               18  \n",
       "27180 40.0000000000       20               17  \n",
       "27181 33.0000000000       14               15  \n",
       "27302 32.0000000000       19                5  \n",
       "\n",
       "[8401 rows x 26 columns]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 휴일일 때\n",
    "df_raw = df_kdhc_heat[df_kdhc_heat['rest_YN'] == 1]\n",
    "col_tar = 'PAJU'\n",
    "# col_tar = 'BUNDANG'\n",
    "# col_tar = 'KANGNAM'\n",
    "\n",
    "# df_kdhc_heat = df_kdhc_heat[[col_tar]]\n",
    "df_raw = df_raw[['YEAR', 'MONTH', 'DAY', 'rest_YN','code_day_of_the_week', 'dist_from_holiday'\n",
    "                , 'HOUR'\n",
    "                , 'PAJU', 'GOYANG', 'SAMSONG', 'JOONGANG'\n",
    "                , 'KANGNAM', 'PANGYO', 'BUNDANG', 'YONGIN', 'GWANGGYO', 'SUWON', 'HWASUNG', 'DONGTAN', 'PYONGTAEK', 'CHEONGJU', 'SEJONG'\n",
    "                , 'KIMHAE', 'DAEGU', 'YANGSAN'\n",
    "                , 'GWANGJU_JEONNAM']]\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method A\n",
    "# seq_length = 5\n",
    "# X, y = create_sequences(df_kdhc_heat, seq_length)\n",
    "\n",
    "# train_size = int(len(df_kdhc_heat) * 0.7)\n",
    "# X_train, y_train = X[:train_size], y[:train_size]\n",
    "# X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "## Method B\n",
    "trainSet, testSet = train_test_split(df_raw, test_size=0.3, shuffle=False)\n",
    "\n",
    "trainXX, trainYY = trainSet.drop([col_tar],axis=1), trainSet[[col_tar]]\n",
    "testXX, testYY = testSet.drop([col_tar],axis=1), testSet[[col_tar]]\n",
    "\n",
    "# trainXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_X, MAX_X = df_raw[col_tar].min(), df_raw[col_tar].max()\n",
    "## MinMax 스케일링\n",
    "def MinMaxScale(array, min, max):\n",
    "    return (array - min) / (max - min)\n",
    "\n",
    "X_train = MinMaxScale(trainXX, MIN_X, MAX_X)\n",
    "y_train = MinMaxScale(trainYY, MIN_X, MAX_X)\n",
    "X_test = MinMaxScale(testXX, MIN_X, MAX_X)\n",
    "y_test = MinMaxScale(testYY, MIN_X, MAX_X)\n",
    "\n",
    "## Tensor 형태로 변환\n",
    "# def make_Tensor(array):\n",
    "#     return torch.from_numpy(array).float()\n",
    "\n",
    "# X_train = make_Tensor(X_train)\n",
    "# y_train = make_Tensor(y_train)\n",
    "# X_test = make_Tensor(X_test)\n",
    "# y_test = make_Tensor(y_test)\n",
    "\n",
    "# plt.plot(df_kdhc_heat.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=1, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7397, grad_fn=<SelectBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.4964], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input = torch.Tensor([y_train[col_tar]])\n",
    "output = c(input)\n",
    "# output\n",
    "\n",
    "w_list = []\n",
    "for param in c.parameters():\n",
    "    w_list.append(param)\n",
    "\n",
    "w = w_list[0]\n",
    "b = w_list[1]\n",
    "\n",
    "w1 = w[0][0][0]\n",
    "\n",
    "print(w1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <PAJU>\n",
    "## rest_YN = 0\n",
    "## ▶ Weight\n",
    "# tensor(-0.7397, grad_fn=<SelectBackward0>)\n",
    "## ▶ Bias\n",
    "# tensor([-0.4964], requires_grad=True)\n",
    "\n",
    "## rest_YN = 1\n",
    "## ▶ Weight\n",
    "# tensor(0.9776, grad_fn=<SelectBackward0>)\n",
    "# Parameter containing:\n",
    "## ▶ Bias\n",
    "# tensor([0.0176], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <BUNDANG>\n",
    "## rest_YN = 0\n",
    "## ▶ Weight\n",
    "# tensor(0.5419, grad_fn=<SelectBackward0>)\n",
    "## ▶ Bias\n",
    "# Parameter containing:\n",
    "# tensor([-0.4190], requires_grad=True)\n",
    "\n",
    "## rest_YN = 1\n",
    "## ▶ Weight\n",
    "# tensor(0.9776, grad_fn=<SelectBackward0>)\n",
    "# Parameter containing:\n",
    "## ▶ Bias\n",
    "# tensor([0.0176], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[737], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstop\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kdhc_heat.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_kdhc_heat['code_day_of_the_week'], df_kdhc_heat['PAJU'], bins=(50, 50), vmax=400)\n",
    "plt.colorbar()\n",
    "plt.xlabel('code_day_of_the_week')\n",
    "plt.ylabel('PAJU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 시간 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 시간 데이터 변환\n",
    "# date_time = pd.to_datetime(df_kdhc_heat.pop('METER_DATE'), format='%d.%m.%Y %H:%M:%S')\n",
    "# timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "# day = 24*60*60\n",
    "# year = (365.2425)*day\n",
    "\n",
    "# df_kdhc_heat['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "# df_kdhc_heat['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "# df_kdhc_heat['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "# df_kdhc_heat['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "# df_kdhc_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.array(df_kdhc_heat['Day sin'])[:25])\n",
    "# plt.plot(np.array(df_kdhc_heat['Day cos'])[:25])\n",
    "# plt.xlabel('Time [h]')\n",
    "# plt.title('Time of day signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df_kdhc_heat.columns)}\n",
    "\n",
    "n = len(df_kdhc_heat)\n",
    "train_df = df_kdhc_heat[0:int(n*0.7)]\n",
    "# val_df = df_kdhc_heat[int(n*0.7):int(n*0.9)]\n",
    "test_df = df_kdhc_heat[int(n*0.7):]\n",
    "\n",
    "num_features = df_kdhc_heat.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "# val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = (df_kdhc_heat - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(df_kdhc_heat.keys(), rotation=90)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

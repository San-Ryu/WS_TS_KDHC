{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Hist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - CODE  \n",
    "    &ensp; : Crawling - 특일 정보 조회 (KASI)\n",
    "\n",
    "  - DATE  \n",
    "    &ensp; 2023-11-29 Created  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 1)   \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 2)    \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 3)   \n",
    "    \n",
    " - DESC  \n",
    "    &ensp; : 전처리 - 한국지역난방공사 열판매량/열공급량   \n",
    "    &emsp; 1) 결측치가 없어서, 그대로 사용  \n",
    "    &emsp;&ensp;&ensp; \n",
    "    &emsp;&ensp;&ensp; (Crawl Code 없음)   \n",
    "    &emsp; 2) \n",
    "\n",
    " - DATA  \n",
    "    &emsp; <\"Input\">  \n",
    "    1) None (Input Dataset)  \n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval : \n",
    "\n",
    "    &emsp; <\"Output\">  \n",
    "    1) Hourly (관측소/년도별 출력)  \n",
    "    &nbsp;df_data_cal.to_csv(data_dir + 'KASI_DATE_D_Final.csv', index = False, encoding='utf-8-sig')  \n",
    "    &emsp;- Columns : ['YEAR', 'MONTH', 'DAY'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'dateKind', 'code_day_of_the_week', 'day_of_the_week'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'rest_YN', 'name_of_holiday', 'dist_from_holiday']\n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval :  \n",
    "    \n",
    "    2) Daily (관측소/년도별 출력)  \n",
    "    &nbsp;df_data_cal_24.to_csv(data_dir + 'KASI_DATE_H_Final.csv', index = False, encoding='utf-8-sig')  \n",
    "    &emsp;- Columns : ['locdate', 'YEAR', 'MONTH', 'DAY'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'dateKind', 'code_day_of_the_week', 'day_of_the_week'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'rest_YN', 'name_of_holiday', 'dist_from_holiday'  \n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;, 'HOUR', 'MINUTE']\n",
    "    &emsp;- Period :   \n",
    "    &emsp;- Interval :  \n",
    "    \n",
    "    \n",
    "\n",
    " - Related Link  \n",
    "    &ensp; : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-01. Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-01. Init_Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region Basic_Import\n",
    "## Basic\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "## Datetime\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import glob\n",
    "from glob import glob\n",
    "import requests\n",
    "import json\n",
    "\n",
    "## 시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "## TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## 정규화\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "## Modeling, Model Training\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "## Model 평가\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score   # model.score   \n",
    "\n",
    "## Excel/CSV\n",
    "import openpyxl, xlrd\n",
    "\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode, unquote, quote_plus\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## Init.\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "#endregion Basic_Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Imported\n"
     ]
    }
   ],
   "source": [
    "## Import_DL\n",
    "str_tar = \"tf\"\n",
    "## For Torch\n",
    "if str_tar == \"torch\":\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.nn.utils import weight_norm\n",
    "    print(\"Torch Imported\")\n",
    "## For TF\n",
    "elif str_tar == \"tf\":\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_addons as tfa\n",
    "    print(\"Tensorflow Imported\")\n",
    "else:\n",
    "    print(\"Error : Cannot be used except for Keywords\")\n",
    "    print(\" : torch / tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import_Local (현재 프로그램에서 미사용)\n",
    "from DEV_Common_Data_Analysis import print_desc_statistic\n",
    "from DEV_Common_Data_Datetime import create_col_ymdhm, create_col_datetime, create_df_dt, conv_midnight_24to00, create_col_weekdays #, validate_date, list_invalidDate, calc_df_dt\n",
    "from DEV_Common_Data_Preprocessing import resample_by_last, find_outlier_Usages, del_outlier_Usages\n",
    "from DEV_Common_Data_Visualization import visualization_df\n",
    "from DEV_KASI_Holiday import KASI_holiDay, KASI_restDay, KASI_anniDay\n",
    "from DEV_KMA_Weather_ASOS import KMA_ASOS_DATA\n",
    "from DEV_KDHC_Usage import KDHC_HEAT_Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-01-02. Config (Directory, Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init_config\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-30 04:01:34.192647\n",
      "2023 / 11 / 30\n",
      "4 : 1\n"
     ]
    }
   ],
   "source": [
    "## Define Todate str\n",
    "str_now_ymd = pd.datetime.now().date()\n",
    "str_now_y = pd.datetime.now().year\n",
    "str_now_m = pd.datetime.now().month\n",
    "str_now_d = pd.datetime.now().day\n",
    "str_now_hr = pd.datetime.now().hour\n",
    "str_now_min = pd.datetime.now().minute\n",
    "\n",
    "print(pd.datetime.now())\n",
    "print(str(str_now_y) + \" / \" + str(str_now_m)  + \" / \" + str(str_now_d))\n",
    "print(str(str_now_hr) + \" : \" + str(str_now_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-02. Data Load (df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-02-01. KDHC Heat Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATA_KDHC_Heat_Provide_Cheongju_2010_2021.csv', 'DATA_KDHC_Heat_Provide_Cheongju_2010_2021_1st_Check.csv', 'DATA_KDHC_Heat_Provide_Sejong_2014_2018.csv', 'DATA_KDHC_Heat_Provide_Sejong_2014_2018_1st_Check.csv', 'DATA_KDHC_Heat_Sell_Branch_201910_202109.csv', 'KDHC_COMB_HEATxWEATHER_2019-2022.csv', 'KDHC_COMB_HEATxWEATHER_2019-2022_complete_analysis.csv', 'KDHC_COMB_HEATxWEATHER_2019-2022_mean_imp.csv', 'KDHC_NATIONAL_HEAT_hr.csv', 'KDHC_NATIONAL_HEAT_RAW_hr.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METER_DATE</th>\n",
       "      <th>day_of_the_week</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>code_day_of_the_week</th>\n",
       "      <th>rest_YN</th>\n",
       "      <th>dist_from_holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>SUWON</th>\n",
       "      <th>HWASUNG</th>\n",
       "      <th>DONGTAN</th>\n",
       "      <th>PYONGTAEK</th>\n",
       "      <th>CHEONGJU</th>\n",
       "      <th>SEJONG</th>\n",
       "      <th>KIMHAE</th>\n",
       "      <th>DAEGU</th>\n",
       "      <th>YANGSAN</th>\n",
       "      <th>GWANGJU_JEONNAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01 01:00:00</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0000000000</td>\n",
       "      <td>11.0000000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.5000000000</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01 01:00:00</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0000000000</td>\n",
       "      <td>11.0000000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.5000000000</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>19.0000000000</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01 02:00:00</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0000000000</td>\n",
       "      <td>12.0000000000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5000000000</td>\n",
       "      <td>13</td>\n",
       "      <td>15.0000000000</td>\n",
       "      <td>7</td>\n",
       "      <td>16.0000000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01 02:00:00</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0000000000</td>\n",
       "      <td>12.0000000000</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5000000000</td>\n",
       "      <td>13</td>\n",
       "      <td>15.0000000000</td>\n",
       "      <td>7</td>\n",
       "      <td>16.0000000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01 03:00:00</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0000000000</td>\n",
       "      <td>12.0000000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.5000000000</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0000000000</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0000000000</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27298</th>\n",
       "      <td>2022-09-30 20:00:00</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0000000000</td>\n",
       "      <td>39.0000000000</td>\n",
       "      <td>61</td>\n",
       "      <td>12.0000000000</td>\n",
       "      <td>36</td>\n",
       "      <td>44.0000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>30.0000000000</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27299</th>\n",
       "      <td>2022-09-30 21:00:00</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0000000000</td>\n",
       "      <td>36.0000000000</td>\n",
       "      <td>55</td>\n",
       "      <td>4.0000000000</td>\n",
       "      <td>30</td>\n",
       "      <td>44.0000000000</td>\n",
       "      <td>11</td>\n",
       "      <td>35.0000000000</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27300</th>\n",
       "      <td>2022-09-30 22:00:00</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0000000000</td>\n",
       "      <td>29.0000000000</td>\n",
       "      <td>45</td>\n",
       "      <td>2.0000000000</td>\n",
       "      <td>27</td>\n",
       "      <td>43.0000000000</td>\n",
       "      <td>12</td>\n",
       "      <td>32.0000000000</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27301</th>\n",
       "      <td>2022-09-30 23:00:00</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0000000000</td>\n",
       "      <td>25.0000000000</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0000000000</td>\n",
       "      <td>25</td>\n",
       "      <td>40.0000000000</td>\n",
       "      <td>11</td>\n",
       "      <td>34.0000000000</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27302</th>\n",
       "      <td>2022-10-01 00:00:00</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0000000000</td>\n",
       "      <td>22.0000000000</td>\n",
       "      <td>26</td>\n",
       "      <td>5.0000000000</td>\n",
       "      <td>21</td>\n",
       "      <td>38.0000000000</td>\n",
       "      <td>11</td>\n",
       "      <td>32.0000000000</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27303 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                METER_DATE day_of_the_week  YEAR  MONTH  DAY  HOUR  MINUTE  \\\n",
       "0      2019-10-01 01:00:00         Tuesday  2019     10    1     1       0   \n",
       "1      2019-10-01 01:00:00         Tuesday  2019     10    1     1       0   \n",
       "2      2019-10-01 02:00:00         Tuesday  2019     10    1     2       0   \n",
       "3      2019-10-01 02:00:00         Tuesday  2019     10    1     2       0   \n",
       "4      2019-10-01 03:00:00         Tuesday  2019     10    1     3       0   \n",
       "...                    ...             ...   ...    ...  ...   ...     ...   \n",
       "27298  2022-09-30 20:00:00          Friday  2022      9   30    20       0   \n",
       "27299  2022-09-30 21:00:00          Friday  2022      9   30    21       0   \n",
       "27300  2022-09-30 22:00:00          Friday  2022      9   30    22       0   \n",
       "27301  2022-09-30 23:00:00          Friday  2022      9   30    23       0   \n",
       "27302  2022-10-01 00:00:00        Saturday  2022     10    1     0       0   \n",
       "\n",
       "       code_day_of_the_week rest_YN dist_from_holiday  ...         SUWON  \\\n",
       "0                         1       0                 2  ... 26.0000000000   \n",
       "1                         1       0                 2  ... 26.0000000000   \n",
       "2                         1       0                 2  ... 29.0000000000   \n",
       "3                         1       0                 2  ... 29.0000000000   \n",
       "4                         1       0                 2  ... 33.0000000000   \n",
       "...                     ...     ...               ...  ...           ...   \n",
       "27298                     4       0                 1  ... 73.0000000000   \n",
       "27299                     4       0                 1  ... 71.0000000000   \n",
       "27300                     4       0                 1  ... 65.0000000000   \n",
       "27301                     4       0                 1  ... 64.0000000000   \n",
       "27302                     5       1                 0  ... 63.0000000000   \n",
       "\n",
       "            HWASUNG  DONGTAN     PYONGTAEK  CHEONGJU        SEJONG  KIMHAE  \\\n",
       "0     11.0000000000       21  0.5000000000        16 18.0000000000       8   \n",
       "1     11.0000000000       21  0.5000000000        16 18.0000000000       8   \n",
       "2     12.0000000000       16  0.5000000000        13 15.0000000000       7   \n",
       "3     12.0000000000       16  0.5000000000        13 15.0000000000       7   \n",
       "4     12.0000000000       14  0.5000000000        10 15.0000000000       7   \n",
       "...             ...      ...           ...       ...           ...     ...   \n",
       "27298 39.0000000000       61 12.0000000000        36 44.0000000000      12   \n",
       "27299 36.0000000000       55  4.0000000000        30 44.0000000000      11   \n",
       "27300 29.0000000000       45  2.0000000000        27 43.0000000000      12   \n",
       "27301 25.0000000000       32  3.0000000000        25 40.0000000000      11   \n",
       "27302 22.0000000000       26  5.0000000000        21 38.0000000000      11   \n",
       "\n",
       "              DAEGU  YANGSAN  GWANGJU_JEONNAM  \n",
       "0     19.0000000000       10                3  \n",
       "1     19.0000000000       10                3  \n",
       "2     16.0000000000        9                2  \n",
       "3     16.0000000000        9                2  \n",
       "4     15.0000000000        8                3  \n",
       "...             ...      ...              ...  \n",
       "27298 30.0000000000       18                6  \n",
       "27299 35.0000000000       22                5  \n",
       "27300 32.0000000000       22                6  \n",
       "27301 34.0000000000       22                6  \n",
       "27302 32.0000000000       19                5  \n",
       "\n",
       "[27303 rows x 46 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define data root directory\n",
    "str_dir_kdhcHeat = \"./data_Energy_KDHC_National_Heat/\"\n",
    "print(os.listdir(str_dir_kdhcHeat))\n",
    "\n",
    "df_kdhc_heat = pd.read_csv(str_dir_kdhcHeat + 'KDHC_COMB_HEATxWEATHER_2019-2022.csv', index_col = 0)\n",
    "df_kdhc_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n",
      "2.4\n",
      "21\n",
      "[22343, 22223, 22151, 22050, 22031, 21994, 21982, 21876, 21864, 21582, 21574, 21503, 21441, 21373, 21358, 21208, 21192, 21130, 21119, 20854, 19430]\n",
      "=============== Descriptive Statistic ===============\n",
      "0.0\n",
      "5.374228697584508\n",
      "4.6\n",
      "6.2829982053254225\n",
      "93.0\n",
      "=============== Descriptive Statistic ===============\n"
     ]
    }
   ],
   "source": [
    "col_tar = 'PYONGTAEK'\n",
    "list_outlierRow = find_outlier_Usages(df_kdhc_heat, col_tar)\n",
    "list_outlierRow = list(reversed(list_outlierRow))\n",
    "print(list_outlierRow)\n",
    "\n",
    "print_desc_statistic(df_kdhc_heat, 'PYONGTAEK')\n",
    "# list_col = ['PAJU', 'GOYANG', 'SAMSONG'\n",
    "#             , 'JOONGANG'\n",
    "#             , 'KANGNAM'\n",
    "#             , 'PANGYO', 'BUNDANG', 'YONGIN', 'GWANGGYO', 'SUWON', 'HWASUNG', 'DONGTAN'\n",
    "#             , 'PYONGTAEK', 'CHEONGJU', 'SEJONG'\n",
    "#             , 'KIMHAE', 'DAEGU', 'YANGSAN'\n",
    "#             , 'GWANGJU_JEONNAM']\n",
    "\n",
    "# for col in list_col:\n",
    "#     visualization_df(df_kdhc_heat, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-03. Create DF_Anomaly Delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-03-01. 완전분석법(Completes Analysis) : 모든 결측값을 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27303, 46)\n",
      "(27282, 46)\n"
     ]
    }
   ],
   "source": [
    "df_complete_analysis = pd.DataFrame.copy(df_kdhc_heat)\n",
    "print(df_complete_analysis.shape)\n",
    "df_complete_analysis = df_complete_analysis.drop(index = list_outlierRow, axis = 0)\n",
    "print(df_complete_analysis.shape)\n",
    "df_complete_analysis.to_csv(str_dir_kdhcHeat + 'KDHC_COMB_HEATxWEATHER_2019-2022_complete_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-03-02. 평균 대치법(Mean Imputation) : 평균값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2829982053254225\n",
      "38.0\n",
      "6.2829982053254225\n",
      "33.0\n",
      "6.2829982053254225\n",
      "36.0\n",
      "6.2829982053254225\n",
      "37.0\n",
      "6.2829982053254225\n",
      "33.0\n",
      "6.2829982053254225\n",
      "37.0\n",
      "6.2829982053254225\n",
      "43.0\n",
      "6.2829982053254225\n",
      "38.0\n",
      "6.2829982053254225\n",
      "39.0\n",
      "6.2829982053254225\n",
      "36.0\n",
      "6.2829982053254225\n",
      "37.0\n",
      "6.2829982053254225\n",
      "32.0\n",
      "6.2829982053254225\n",
      "32.0\n",
      "6.2829982053254225\n",
      "35.0\n",
      "6.2829982053254225\n",
      "36.0\n",
      "6.2829982053254225\n",
      "37.0\n",
      "6.2829982053254225\n",
      "36.0\n",
      "6.2829982053254225\n",
      "32.0\n",
      "6.2829982053254225\n",
      "37.0\n",
      "6.2829982053254225\n",
      "38.0\n",
      "6.2829982053254225\n",
      "93.0\n",
      "6.2829982053254225\n"
     ]
    }
   ],
   "source": [
    "df_mean_imp = pd.DataFrame.copy(df_kdhc_heat)\n",
    "flt_mean = np.mean(df_mean_imp[col_tar])\n",
    "print(flt_mean)\n",
    "for i in list_outlierRow:\n",
    "    print(df_mean_imp[col_tar].iloc[i])\n",
    "    df_mean_imp[col_tar].iloc[i] = flt_mean\n",
    "    print(df_mean_imp[col_tar].iloc[i])\n",
    "df_mean_imp.to_csv(str_dir_kdhcHeat + 'KDHC_COMB_HEATxWEATHER_2019-2022_mean_imp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-03-03. 1~2주전 동일 시간 대치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prevWeek_imp = pd.DataFrame.copy(df_kdhc_heat)\n",
    "for i in list_outlierRow:\n",
    "    print(df_mean_imp[col_tar].iloc[i])\n",
    "    df_mean_imp[col_tar].iloc[i] = \n",
    "    print(df_mean_imp[col_tar].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01-03-04. IQR 탐지 기반 Lienar Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n",
      "2.4\n",
      "21\n",
      "14.0\n",
      "2.4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df_linearReg = pd.DataFrame.copy(df_kdhc_heat)\n",
    "\n",
    "df_linearReg = del_outlier_Usages(df_linearReg, col_tar)\n",
    "find_outlier_Usages(df_linearReg, col_tar)\n",
    "df_linearReg.to_csv(str_dir_kdhcHeat + 'KDHC_COMB_HEATxWEATHER_2019-2022_linearReg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 회귀 대치법(Regression Imputation) : \n",
    "\n",
    "## 단순확률 대치법(Single Stochastic Imputation) : \n",
    "\n",
    "## 최근접 대치법 (Nearest-Neighbor Imputation) : 계층\n",
    "\n",
    "## \n",
    "\n",
    "\n",
    "## 최근접+평균 대치법 : 계층을 나눈 후, 앞뒤값의 평균에 해당하는 계층의 평균값으로 대치\n",
    "\n",
    "## 동일요일 / 시간대의 평균값으로 대치\n",
    "df_sameWeekdayTime = pd.DataFrame.copy(df_kdhc_heat)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
